{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c3f8ae-a0eb-4563-94c3-7e1336715716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35f7d9e3-0869-4ce9-be91-76938035e787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3297\n",
      "0.16574624158406065 0.3114123715955396 0.8198593291495693 0.8547645909981955 0.24998919092138122 0.970237533262574 0.5951163207378447\n",
      "3297\n",
      "0.16574624158406065 0.9113480848578538 0.8198593291495693 0.8547645909981955 0.8268080505663535 0.970237533262574 0.5951163207378447\n",
      "3297\n",
      "0.200726550812963 0.9113480848578538 0.8198593291495693 0.7605280565989978 0.8268080505663535 0.970237533262574 0.859036534402326\n"
     ]
    }
   ],
   "source": [
    "seqs = []\n",
    "refs = []\n",
    "scores = []\n",
    "for f in range(1, 4):\n",
    "    scores1 = np.load(f\"/home/ali.lawati/mol-incontext/input/embed/mmcl_attr-chebi-{f}-epochs300-loop.mistral-7B.scores.npy\")\n",
    "    print(len(scores1))\n",
    "    print(scores1[7], scores1[9], scores1[18], scores1[19], scores1[21], scores1[29], scores1[66])\n",
    "    embeds1 = np.load(f\"/home/ali.lawati/mol-incontext/input/embed/mmcl_attr-chebi-{f}-epochs300-embeds.npz\")\n",
    "    seqs1 = torch.tensor(embeds1['embeds']) #.flip(dims=[1])] #torch.cat([torch.zeros(3297, 5-f, 64), torch.tensor(embeds1['embeds']).flip(dims=[1])], dim=1)\n",
    "    #print(embeds1['embeds'][7])\n",
    "    refs1 = np.reshape(embeds1['test_pool'], (embeds1['test_pool'].shape[0],1,-1))\n",
    "    seqs.append(seqs1)\n",
    "    refs.append(torch.tensor(refs1))\n",
    "    scores.append(scores1)\n",
    "\n",
    "#seqs_tensor = torch.cat(seqs)\n",
    "#scores_tensor = torch.tensor(np.concatenate(scores))\n",
    "#refs_tensor = torch.tensor(np.concatenate(refs))\n",
    "\n",
    "l_scores_tensor = torch.tensor(scores[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "089820e8-95eb-4006-ad05-3a009c877e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.where((scores[2] > scores[1]) & (scores[2] > scores[0]) & (scores[2] > .7))[0]\n",
    "dmb = np.where((scores[2] < scores[1]) & (scores[1] < scores[0]) & (scores[0] < .5))[0]\n",
    "len(dmb)\n",
    "\n",
    "#create_expert_trajs(refs[2][dmb], seqs[2][dmb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "220fa6b4-a49a-4c21-aa3b-9ed6a9fb5684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6021e-02, -2.3202e-02,  4.2733e-02,  1.6160e-01, -9.1340e-05,\n",
       "          9.8902e-02, -4.4263e-02, -1.5083e-01,  1.2593e-02, -3.1048e-02,\n",
       "         -1.2606e-01,  1.1833e-01,  1.0150e-01,  2.4165e-03,  2.6916e-02,\n",
       "         -2.0499e-02, -7.3339e-03,  3.7603e-02,  3.6223e-02, -3.8263e-02,\n",
       "          6.1981e-02, -3.7109e-02,  6.2713e-03,  1.0167e-01,  9.5623e-02,\n",
       "         -1.3048e-01, -4.3612e-02, -1.1486e-01, -5.3162e-02, -7.1722e-02,\n",
       "          9.7927e-02, -4.6405e-02, -2.3655e-01,  1.1613e-01, -3.3322e-02,\n",
       "          7.2241e-02,  1.9261e-02, -4.4375e-03,  6.7154e-02,  1.3967e-01,\n",
       "         -8.5062e-02, -1.8700e-02, -4.7262e-02,  9.1540e-02, -1.1362e-01,\n",
       "          6.5768e-02,  5.5655e-02, -4.9894e-02,  3.6377e-02,  8.4522e-03,\n",
       "          3.1113e-02, -7.9134e-02,  1.0564e-01,  9.7155e-02,  1.6680e-01,\n",
       "          1.1739e-01,  6.5591e-03, -2.8080e-02,  1.0765e-01, -1.1404e-01,\n",
       "         -1.5652e-02, -2.9581e-02,  9.4983e-02, -1.4238e-01],\n",
       "        [ 1.8196e-02, -3.0360e-02,  3.9709e-02,  1.6030e-01, -7.3337e-03,\n",
       "          9.8471e-02, -6.0584e-02, -1.5843e-01,  1.0685e-02, -2.4892e-02,\n",
       "         -1.3383e-01,  1.1443e-01,  1.1563e-01,  3.4787e-03,  2.4869e-02,\n",
       "         -1.7899e-02,  2.9825e-03,  3.0149e-02,  3.4805e-02, -4.4544e-02,\n",
       "          7.5353e-02, -4.2531e-02,  1.1549e-02,  1.0012e-01,  1.0454e-01,\n",
       "         -1.3813e-01, -4.0615e-02, -1.2479e-01, -5.2731e-02, -6.8114e-02,\n",
       "          8.7143e-02, -3.9907e-02, -2.4063e-01,  1.2714e-01, -2.2092e-02,\n",
       "          7.8852e-02,  6.6189e-03, -1.9982e-03,  6.8758e-02,  1.4814e-01,\n",
       "         -8.1016e-02, -2.6836e-02, -4.9176e-02,  1.0136e-01, -1.1108e-01,\n",
       "          6.6884e-02,  6.2800e-02, -3.2107e-02,  3.5643e-02,  4.0911e-03,\n",
       "          2.4918e-02, -7.5569e-02,  1.0503e-01,  9.5415e-02,  1.6105e-01,\n",
       "          1.0707e-01,  1.3557e-02, -3.3422e-02,  1.1221e-01, -1.0995e-01,\n",
       "         -2.4060e-02, -3.1738e-02,  7.8840e-02, -1.2780e-01],\n",
       "        [ 1.2881e-02, -2.9189e-02,  4.2987e-02,  1.5473e-01, -8.7692e-03,\n",
       "          1.0103e-01, -4.1794e-02, -1.3812e-01,  1.4894e-02, -1.7488e-02,\n",
       "         -1.1362e-01,  1.1564e-01,  1.0384e-01,  6.8005e-03,  2.9378e-02,\n",
       "         -2.2651e-02, -7.0192e-03,  3.4640e-02,  3.1471e-02, -2.8574e-02,\n",
       "          5.9424e-02, -2.8971e-02,  1.7597e-04,  9.3750e-02,  7.7515e-02,\n",
       "         -1.2519e-01, -2.6164e-02, -1.2284e-01, -5.5396e-02, -6.5585e-02,\n",
       "          8.2357e-02, -3.5775e-02, -2.1492e-01,  1.0069e-01, -3.1878e-02,\n",
       "          7.5324e-02,  7.6456e-03, -1.0496e-02,  6.7114e-02,  1.3739e-01,\n",
       "         -7.1870e-02, -1.2310e-02, -5.6175e-02,  9.1199e-02, -1.1290e-01,\n",
       "          6.7344e-02,  3.6163e-02, -5.0795e-02,  3.2064e-02,  1.2480e-02,\n",
       "          1.8118e-02, -7.5728e-02,  8.4478e-02,  1.0848e-01,  1.4253e-01,\n",
       "          9.9564e-02,  1.2422e-02, -3.6413e-02,  1.1150e-01, -1.0913e-01,\n",
       "         -1.9466e-02, -3.1183e-02,  8.1118e-02, -1.1195e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs[2][idx].shape\n",
    "refs[2][idx].shape\n",
    "\n",
    "refs[2][idx[0]]+seqs[2][idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75dc6236-00ee-4bab-9cb8-ae0d262ecaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([129, 3, 64]) torch.Size([129, 3, 64]) torch.Size([129, 3, 64])\n"
     ]
    }
   ],
   "source": [
    "def create_expert_states(refs, seqs):\n",
    "    combined = torch.cat([refs, seqs], dim=1)  # Shape: [batch, L, dim]\n",
    "    cumulative_sum = torch.cumsum(combined, dim=1)  # Shape: [batch, L, dim]\n",
    "    return cumulative_sum\n",
    "\n",
    "def create_triplets(states, actions):\n",
    "    next_states = states[:, 1:, :]  # Shape: [BATCH, 3, 64]\n",
    "    current_states = states[:, :3, :]  # Shape: [BATCH, 3, 64]\n",
    "    #triplets = torch.stack([current_states, actions, next_states], dim=2)\n",
    "    #return triplets\n",
    "    return current_states, actions, next_states\n",
    "actions = seqs[2][idx]\n",
    "states = create_expert_states(refs[2][idx], seqs[2][idx])\n",
    "expert_trajs = create_triplets(states, actions)\n",
    "\n",
    "                               \n",
    "\n",
    "\n",
    "#print(seqs[2][idx][0])\n",
    "a = create_triplets(states, actions)\n",
    "print(a[0].shape, a[1].shape, a[2].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a2b594a-b15d-4ebf-977d-ea37fd10506b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([129])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(actions.shape[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c94c9efe-5796-46c3-8d38-c35192a351fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64])\n",
      "p_action.shape torch.Size([32, 64])\n",
      "torch.Size([32, 1]) torch.Size([32, 3297, 64])\n",
      "p_state.shape torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def create_policy_traj(states, actions, B=32, ML=3):\n",
    "    actions = actions.reshape(-1 ,64)\n",
    "    states = states.reshape(-1 ,64)\n",
    "    \n",
    "    actions_B = actions.unsqueeze(0).expand(B, -1, 64)\n",
    "    states_B = states.unsqueeze(0).expand(B, -1, 64)\n",
    "\n",
    "    sample_sizes = torch.randint(1, ML, (B,))\n",
    "    mask = (torch.arange(ML-1).expand(B, -1) < sample_sizes.unsqueeze(1))\n",
    "    probabilities = torch.ones(B, actions.shape[0])\n",
    "\n",
    "    indices = torch.multinomial(probabilities, ML-1, replacement=False)\n",
    "    actions_s = actions_B[torch.arange(32).unsqueeze(1), indices]\n",
    "    result = actions_s*mask.unsqueeze(-1).float()\n",
    "    \n",
    "    action_add = result.sum(dim=1)\n",
    "    indices = torch.multinomial(torch.ones(B, actions.shape[0]), 1, replacement=False)\n",
    "    p_action = actions_B[torch.arange(32).unsqueeze(1), indices].squeeze(1)\n",
    "    indices = torch.multinomial(torch.ones(B, states.shape[0]), 1, replacement=False)\n",
    "    p_state = states_B[torch.arange(32).unsqueeze(1), indices].squeeze(1)\n",
    "    \n",
    "    p_state = p_state + action_add\n",
    "    p_next_state = p_action + p_state\n",
    "\n",
    "    return p_state, p_action, p_next_state\n",
    "\n",
    "x = create_policy_traj(refs[2], seqs[2])\n",
    "print(x[0].shape, x[1].shape, x[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "237a063a-80c4-4546-a365-173e4b4fde8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 1, 1, 2, 3, 2, 3, 3, 2, 3, 3, 3, 3, 1, 3, 3, 2, 3, 2, 3, 3, 1, 3,\n",
       "        2, 2, 3, 1, 1, 2, 3, 3, 3, 3, 3, 1, 1, 1, 1, 2, 3, 1, 3, 2, 2, 2, 2, 2,\n",
       "        1, 1, 2, 3, 2, 3, 2, 2, 2, 3, 3, 3, 1, 2, 2, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sizes = torch.randint(1, 4, (64,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d3bf605a-28b9-48d5-b50d-92924cc4d5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([387, 64])\n",
      "indices torch.Size([32, 3])\n",
      "actions torch.Size([387, 64])\n",
      "mask torch.Size([32, 3])\n",
      "torch.Size([32, 387, 64])\n",
      "torch.Size([32, 3, 64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (32) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m actions_s \u001b[38;5;241m=\u001b[39m actions_B[torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m32\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), indices]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(actions_s\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 16\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mactions_s\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (32) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "B = 32\n",
    "\n",
    "actions = actions.reshape(-1 ,64)\n",
    "print(actions.shape)\n",
    "sample_sizes = torch.randint(1, 4, (B,))\n",
    "mask = (torch.arange(3).expand(B, -1) < sample_sizes.unsqueeze(1))\n",
    "probabilities = torch.ones(B, actions.shape[0])\n",
    "indices = torch.multinomial(probabilities, 3, replacement=False)\n",
    "print('indices', indices.shape)\n",
    "print('actions', actions.shape)\n",
    "print('mask', mask.shape)\n",
    "actions_B = actions.unsqueeze(0).expand(B, -1, 64)\n",
    "print(actions_B.shape)\n",
    "actions_s = actions_B[torch.arange(32).unsqueeze(1), indices]\n",
    "print(actions_s.shape)\n",
    "result = actions_s*mask.unsqueeze(-1).float()\n",
    "print(result.shape)\n",
    "print(result.sum(dim=1).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbb6f4bf-ac3c-419d-869e-80d4091867e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True, False],\n",
       "        [ True,  True, False],\n",
       "        [ True, False, False],\n",
       "        [ True, False, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True, False, False],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True, False, False],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True],\n",
       "        [ True, False, False],\n",
       "        [ True, False, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True, False, False],\n",
       "        [ True, False, False],\n",
       "        [ True, False, False],\n",
       "        [ True, False, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True],\n",
       "        [ True, False, False],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True, False],\n",
       "        [ True, False, False],\n",
       "        [ True, False, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True, False, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " (torch.arange(3).expand(6, -1) < sample_sizes.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecb9b8f-8d83-49fb-8af0-a676a36f73fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
